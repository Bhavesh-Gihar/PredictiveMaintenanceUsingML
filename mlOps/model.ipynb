{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"DTmodel\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/home/bhavesh/Downloads/predictive_maintenance.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"UDI\", \"Product ID\", \"Type\", \"Failure Type\"]\n",
    "df = df.drop(*columns_to_drop)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = df.columns[:-1]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, test_data) = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol=\"Target\", featuresCol=\"features\")\n",
    "dt_model = dt.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dt_model.transform(test_data)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Target\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Test Accuracy = %g\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# path = \"/home/bhavesh/Documents/PredictiveMaintenanceUsingML/mlOps/dataset/predictive_maintenance.csv\"\n",
    "# df = pd.read_csv(path)\n",
    "# X = df.drop(['Target'], axis=1)\n",
    "# y = df['Target']\n",
    "\n",
    "# columns_to_drop = [\"UDI\", \"Product ID\", \"Type\", \"Failure Type\"]\n",
    "# X = X.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# # Split data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Define the model\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Dense(units=1, input_shape=[5])  # Single unit dense layer for linear regression\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train, epochs=100)\n",
    "\n",
    "# # Save the TensorFlow model\n",
    "# model.save('linear_regression_model.h5')\n",
    "\n",
    "# # Convert the TensorFlow model to TensorFlow Lite\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# # Save the TFLite model\n",
    "# with open('linear_regression_model.tflite', 'wb') as f:\n",
    "#     f.write(tflite_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.06501729264401601\n",
      "1 0.07286664205648674\n",
      "1 0.03868347269783445\n",
      "1 0.1901192216086418\n",
      "1 0.28301401742195464\n",
      "1 0.20492844051368952\n",
      "1 0.17538997706570347\n",
      "1 0.12084467656222442\n",
      "1 0.1879036902806377\n",
      "1 0.22201624733546677\n",
      "1 -0.02839025731782674\n",
      "1 0.28681416387962266\n",
      "1 0.17374158687369778\n",
      "1 0.1861899053318945\n",
      "1 0.03963645407943672\n",
      "1 0.11056270880766639\n",
      "1 0.1203399797860849\n",
      "1 0.1835590958938691\n",
      "1 0.08175785344336228\n",
      "1 0.09344553557262314\n",
      "1 0.20710463451618977\n",
      "1 -0.0005970706553533045\n",
      "1 0.09223501464574868\n",
      "1 0.06022070332040386\n",
      "1 0.2007056190744012\n",
      "1 0.16275235501374818\n",
      "1 0.12734722243020768\n",
      "1 -0.03129789158905916\n",
      "1 0.3230150890949435\n",
      "1 0.1652289364096169\n",
      "1 0.11128655868767723\n",
      "1 0.24943503543733359\n",
      "1 0.299716706359864\n",
      "1 0.1886063160164102\n",
      "1 0.19608621970236695\n",
      "1 0.3394224872636322\n",
      "1 0.23335484310992727\n",
      "1 0.31124398335106873\n",
      "1 0.2406894903017167\n",
      "1 0.12285164659447978\n",
      "1 0.304292717247006\n",
      "1 0.18639399436313364\n",
      "1 0.10609373813360157\n",
      "1 -0.004008493112832356\n",
      "1 -0.023220475632597104\n",
      "1 0.23215065980742078\n",
      "1 0.16054893642008716\n",
      "1 0.17202057604900656\n",
      "1 0.26659027203677854\n",
      "1 0.27159193807171134\n",
      "1 0.24402866744306206\n",
      "1 0.03575322217312649\n",
      "1 0.2424613352734346\n",
      "1 0.2546807032330025\n",
      "1 0.08064063775911312\n",
      "1 0.3447614474514331\n",
      "1 0.020547636292986615\n",
      "1 0.23585910594682713\n",
      "1 0.14557303983363834\n",
      "1 0.04104342546756223\n",
      "1 0.25415009454213133\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "path = \"/home/bhavesh/Documents/PredictiveMaintenanceUsingML/mlOps/dataset/predictive_maintenance.csv\"\n",
    "df = pd.read_csv(path)\n",
    "X = df.drop(['Target'], axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "columns_to_drop = [\"UDI\", \"Product ID\", \"Type\", \"Failure Type\"]\n",
    "X = X.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "for index, value in enumerate(y_test):\n",
    "    if(value == 1):\n",
    "        print(value, end=\" \")\n",
    "        print(y_pred[index])\n",
    "\n",
    "# # Calculate accuracy\n",
    "# accuracy = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# # Print the accuracy\n",
    "# print(\"MSE of Linear Reg:\", accuracy)\n",
    "\n",
    "# with open('/home/bhavesh/Documents/PredictiveMaintenanceUsingML/client/model.pkl', 'wb') as f:\n",
    "#     pickle.dump(reg, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
